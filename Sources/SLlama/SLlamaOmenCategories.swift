import Foundation
import Omen

// MARK: - SLlama Omen Categories

/// ðŸ”® SLlama-specific mystical categories extending Omen
///
/// **EXTENSIBILITY EXAMPLE**: This demonstrates how users can extend Omen's core
/// categories with domain-specific ones while maintaining the mystical theming.
public enum SLlamaOmenCategories {
    /// Machine Learning and AI-specific mystical categories
    public enum AI: String, OmenCategory, CaseIterable {
        case model = "Model" // ðŸ§  Intelligence omens
        case context = "Context" // ðŸŽ¯ Contextual omens
        case sampler = "Sampler" // ðŸŽ² Randomness omens
        case inference = "Inference" // ðŸ” Prediction omens
        case tokenizer = "Tokenizer" // ðŸ“ Language omens
        case quantization = "Quantization" // âš–ï¸ Precision omens
        case adapter = "Adapter" // ðŸ”— Adaptation omens
        case batch = "Batch" // ðŸ“¦ Batch omens
        case systemInfo = "SystemInfo" // ðŸ”§ System omens

        public var description: String {
            switch self {
                case .model:
                    "ðŸ§  Model loading, validation, and management â€” intelligence omens"
                case .context:
                    "ðŸŽ¯ Context creation, configuration, and operations â€” contextual omens"
                case .sampler:
                    "ðŸŽ² Token sampling strategies and chains â€” randomness omens"
                case .inference:
                    "ðŸ” Inference operations (encode/decode) â€” prediction omens"
                case .tokenizer:
                    "ðŸ“ Text tokenization and vocabulary â€” language omens"
                case .quantization:
                    "âš–ï¸ Model quantization operations â€” precision omens"
                case .adapter:
                    "ðŸ”— LoRA adapters and control vectors â€” adaptation omens"
                case .batch:
                    "ðŸ“¦ Batch processing operations â€” batch omens"
                case .systemInfo:
                    "ðŸ”§ System capabilities and hardware information â€” system omens"
            }
        }

        public var symbol: String {
            switch self {
                case .model: "ðŸ§ "
                case .context: "ðŸŽ¯"
                case .sampler: "ðŸŽ²"
                case .inference: "ðŸ”"
                case .tokenizer: "ðŸ“"
                case .quantization: "âš–ï¸"
                case .adapter: "ðŸ”—"
                case .batch: "ðŸ“¦"
                case .systemInfo: "ðŸ”§"
            }
        }
    }

    /// Register all SLlama categories with Omen at startup
    ///
    /// **USAGE PATTERN**: Call this once during app initialization to make
    /// SLlama categories available throughout the application.
    public static func registerAll() {
        for category in AI.allCases {
            OmenCategories.register(category)
        }
    }
}

// MARK: - Convenience Extensions for SLlama

public extension Omen {
    // MARK: - AI/ML Category Shortcuts

    /// ðŸ§  Model omen â€” intelligence visions
    @inlinable
    static func model(_ message: @autoclosure () -> String) {
        info(SLlamaOmenCategories.AI.model, message())
    }

    /// ðŸ§  Model debug whisper
    @inlinable
    static func modelDebug(_ message: @autoclosure () -> String) {
        debug(SLlamaOmenCategories.AI.model, message())
    }

    /// ðŸ§  Model error portent
    @inlinable
    static func modelError(_ message: @autoclosure () -> String) {
        error(SLlamaOmenCategories.AI.model, message())
    }

    /// ðŸŽ¯ Context omen â€” contextual visions
    @inlinable
    static func context(_ message: @autoclosure () -> String) {
        info(SLlamaOmenCategories.AI.context, message())
    }

    /// ðŸŽ² Sampler omen â€” randomness visions
    @inlinable
    static func sampler(_ message: @autoclosure () -> String) {
        info(SLlamaOmenCategories.AI.sampler, message())
    }

    /// ðŸ” Inference omen â€” prediction visions
    @inlinable
    static func inference(_ message: @autoclosure () -> String) {
        info(SLlamaOmenCategories.AI.inference, message())
    }

    /// ðŸ“ Tokenizer omen â€” language visions
    @inlinable
    static func tokenizer(_ message: @autoclosure () -> String) {
        info(SLlamaOmenCategories.AI.tokenizer, message())
    }

    /// âš–ï¸ Quantization omen â€” precision visions
    @inlinable
    static func quantization(_ message: @autoclosure () -> String) {
        info(SLlamaOmenCategories.AI.quantization, message())
    }

    /// ðŸ”— Adapter omen â€” adaptation visions
    @inlinable
    static func adapter(_ message: @autoclosure () -> String) {
        info(SLlamaOmenCategories.AI.adapter, message())
    }

    /// ðŸ“¦ Batch omen â€” batch visions
    @inlinable
    static func batch(_ message: @autoclosure () -> String) {
        info(SLlamaOmenCategories.AI.batch, message())
    }

    /// ðŸ”§ System info omen â€” hardware visions
    @inlinable
    static func systemInfo(_ message: @autoclosure () -> String) {
        info(SLlamaOmenCategories.AI.systemInfo, message())
    }

    /// ðŸ”§ System debug whisper
    @inlinable
    static func systemDebug(_ message: @autoclosure () -> String) {
        debug(SLlamaOmenCategories.AI.systemInfo, message())
    }
}
